{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5184e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Installing required packages \"\"\"\n",
    "\n",
    "%pip install --quiet faster-whisper psutil pytubefix pandas fastapi spacy numba openai pydub ruff tqdm\n",
    "# %pip install faster-whisper psutil pytubefix pandas fastapi spacy numba openai pydub ruff tqdm\n",
    "# %pip install faster-whisper==1.2.0 psutil==7.0.0 pytubefix==9.4.1 pandas==2.3.1 fastapi==0.116.1 spacy==3.8.7 numba==0.61.2 openai==1.100.1 pydub==0.25.1 ruff==0.12.9 tqdm==4.67.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732408d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\GitHub\\Random\\bulk_transcribe_youtube_videos_from_playlist\\venv\\Lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "b:\\GitHub\\Random\\bulk_transcribe_youtube_videos_from_playlist\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Importing Libs \"\"\"\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import datetime\n",
    "import traceback\n",
    "from pytubefix import YouTube, Playlist\n",
    "import pandas as pd\n",
    "from faster_whisper import WhisperModel\n",
    "from numba import cuda\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "# import psutil # Unused\n",
    "# import openai # Unused\n",
    "# import spacy.cli # Unused\n",
    "# from concurrent.futures import ProcessPoolExecutor # Unused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "328198e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Constants and Configurations \"\"\"\n",
    "\n",
    "# Constants for pricing\n",
    "WHISPER_COST_PER_MINUTE = 0.006\n",
    "\n",
    "use_spacy_for_sentence_splitting = 1\n",
    "use_openai_api_for_transcription = 0\n",
    "openai_api_key = 'REPLACE_WITH_YOUR_API_KEY'\n",
    "max_simultaneous_youtube_downloads = 4\n",
    "\n",
    "disable_cuda_override = 0\n",
    "my_cuda_path = 'B:/Programas/Programming/CUDA/bin'\n",
    "os.environ[\"PATH\"] += os.pathsep + my_cuda_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a566f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Transcription Modes \"\"\"\n",
    "\n",
    "convert_single_video = 0\n",
    "single_video_url = ''\n",
    "# single_video_url = 'https://youtu.be/OYAPlnJfepw' # Estrutura do DNA e da cromatina - Parte 4\n",
    "# single_video_url = 'https://youtu.be/jxO6D8eC9JQ' # Replicação do DNA - Parte 1\n",
    "# single_video_url = 'https://youtu.be/w1bS7iCOJQA' # Estrutura do RNA transcrição e processamento do RNA - Parte 2\n",
    "playlist_url = 'https://www.youtube.com/playlist?list=PLC50eYMsqq-jhTtuOaLCqCdg4sz5GiwaC'\n",
    "\n",
    "# - Estrutura do DNA e da cromatina - Parte 4: https://youtu.be/OYAPlnJfepw\n",
    "# - Replicação do DNA - Parte 1: https://youtu.be/jxO6D8eC9JQ\n",
    "# - Estrutura do RNA transcrição e processamento do RNA - Parte 2: https://youtu.be/w1bS7iCOJQA\n",
    "\n",
    "modes = {\n",
    "    'playlists': [],\n",
    "    'single_videos': [],\n",
    "    'downloaded_media': [],\n",
    "}\n",
    "\n",
    "default_path = 'code/'\n",
    "\n",
    "paths = {\n",
    "    'audio': default_path+'downloaded_audio',\n",
    "    'combined': default_path+'generated_transcript_combined_texts',\n",
    "    'metatable': default_path+'generated_transcript_metadata_tables',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7ae432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? False\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Checking CUDA Availability \"\"\"\n",
    "\n",
    "print(\"Is CUDA available?\", cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Auxiliary Functions \"\"\"\n",
    "\n",
    "def add_to_system_path(new_path):\n",
    "    if new_path not in os.environ[\"PATH\"].split(os.pathsep):\n",
    "        os.environ[\"PATH\"] = new_path + os.pathsep + os.environ[\"PATH\"]\n",
    "    if sys.platform == \"win32\" and ' ' in new_path and not new_path.startswith('\"') and not new_path.endswith('\"'):\n",
    "        os.environ[\"PATH\"] = f'\"{new_path}\"' + os.pathsep + \\\n",
    "            os.environ[\"PATH\"].replace(new_path, \"\")\n",
    "\n",
    "def get_cuda_toolkit_path():\n",
    "    custom_cuda_path = my_cuda_path\n",
    "    if os.path.exists(custom_cuda_path):\n",
    "        return custom_cuda_path\n",
    "    home_dir = os.path.expanduser('~')\n",
    "    if sys.platform in [\"win32\", \"linux\", \"linux2\", \"darwin\"]:\n",
    "        anaconda_base_path = os.path.join(home_dir, \"anaconda3\", \"pkgs\")\n",
    "    cuda_glob_pattern = os.path.join(\n",
    "        anaconda_base_path, \"cudatoolkit-*\", \"Library\", \"bin\")\n",
    "    cuda_paths = glob.glob(cuda_glob_pattern)\n",
    "    if cuda_paths:\n",
    "        return cuda_paths[0]\n",
    "    return None\n",
    "\n",
    "def clean_filename(title):\n",
    "    title = re.sub(r'[^\\w\\s-]', '', title)\n",
    "    return re.sub(r'[-\\s]+', '_', title).strip().lower()\n",
    "\n",
    "async def download_audio(video):\n",
    "    filename = clean_filename(video.title)\n",
    "    # base_filename = filename\n",
    "    # counter = 1\n",
    "    audio_dir = 'downloaded_audio'\n",
    "    audio_file_path = os.path.join(audio_dir, f\"{filename}.mp4\")\n",
    "    # Verifica se o arquivo já existe antes de tentar baixar\n",
    "    while os.path.exists(audio_file_path):\n",
    "        # Se já existe, retorna imediatamente\n",
    "        return audio_file_path, filename\n",
    "        # Se quiser permitir múltiplos arquivos com nomes diferentes, remova o return acima e mantenha o loop\n",
    "        # filename = f\"{base_filename}_{counter}\"\n",
    "        # audio_file_path = os.path.join(audio_dir, f\"{filename}.mp4\")\n",
    "        # counter += 1\n",
    "    # Se não existe, faz o download normalmente\n",
    "    stream = video.streams.filter(only_audio=True).first()\n",
    "    if stream is None:\n",
    "        raise ValueError(f\"No audio stream found for video: {video.title}\")\n",
    "    try:\n",
    "        os.makedirs(audio_dir, exist_ok=True)\n",
    "        audio_file_path = stream.download(\n",
    "            output_path=audio_dir, filename=f\"{filename}.mp4\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading video {video.title}: {e}\")\n",
    "        return None, None\n",
    "    return audio_file_path, filename\n",
    "\n",
    "def estimate_whisper_transcription_cost(audio_duration_seconds):\n",
    "    audio_duration_minutes = audio_duration_seconds / 60\n",
    "    estimated_cost = audio_duration_minutes * WHISPER_COST_PER_MINUTE\n",
    "    print(f\"\\n=== Estimated Whisper Transcription Cost ===\")\n",
    "    print(f\"Audio Duration: {audio_duration_minutes:.2f} minutes\")\n",
    "    print(f\"Estimated Cost: ${estimated_cost:.4f}\\n\")\n",
    "    return estimated_cost\n",
    "\n",
    "async def get_audio_duration(audio_file_path):\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    return len(audio) / 1000  # pydub returns duration in milliseconds\n",
    "\n",
    "def remove_unwanted_segments_from_json(json_file_path, unwanted_text=\"Subtitles by the Amara.org community\"):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    original_segment_count = len(data)\n",
    "    filtered_data = [\n",
    "        segment for segment in data if unwanted_text not in segment['text']]\n",
    "    filtered_segment_count = len(filtered_data)\n",
    "    if original_segment_count != filtered_segment_count:\n",
    "        with open(json_file_path, 'w') as json_file:\n",
    "            json.dump(filtered_data, json_file, indent=4)\n",
    "        print(\n",
    "            f\"Removed {original_segment_count - filtered_segment_count} unwanted segments from {json_file_path}.\")\n",
    "    else:\n",
    "        print(f\"No unwanted segments found in {json_file_path}.\")\n",
    "\n",
    "async def compute_transcript_with_whisper_from_audio_func(audio_file_path, audio_file_name, audio_file_size_mb):\n",
    "    cuda_toolkit_path = get_cuda_toolkit_path()\n",
    "    if cuda_toolkit_path:\n",
    "        add_to_system_path(cuda_toolkit_path)\n",
    "    combined_transcript_text = \"\"\n",
    "    combined_transcript_text_list_of_metadata_dicts = []\n",
    "    list_of_transcript_sentences = []\n",
    "    if use_openai_api_for_transcription:\n",
    "        print(f\"Using OpenAI API for transcription of {audio_file_name}...\")\n",
    "        from openai import AsyncOpenAI\n",
    "        client = AsyncOpenAI(api_key=openai_api_key)\n",
    "        audio_duration_seconds = await get_audio_duration(audio_file_path)\n",
    "        estimate_whisper_transcription_cost(audio_duration_seconds)\n",
    "        with open(audio_file_path, \"rb\") as audio_file:\n",
    "            response = await client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                response_format=\"verbose_json\"\n",
    "            )\n",
    "        # Access the response content\n",
    "        response_data = json.loads(response.model_dump_json())\n",
    "        segments = response_data.get('segments', [])\n",
    "        combined_transcript_text = response_data.get('text', \"\")\n",
    "        combined_transcript_text_list_of_metadata_dicts = [\n",
    "            {\n",
    "                \"start\": segment.get('start', 0),\n",
    "                \"end\": segment.get('end', 0),\n",
    "                \"text\": segment.get('text', \"\"),\n",
    "                \"avg_logprob\": segment.get('avg_logprob', 0)\n",
    "            }\n",
    "            for segment in segments\n",
    "        ]\n",
    "    else:\n",
    "        print(\n",
    "            f\"\\nUsing local Whisper model for transcription of {audio_file_name}...\")\n",
    "        if cuda.is_available() and not disable_cuda_override:\n",
    "            print(\"CUDA is available. Using GPU for transcription.\")\n",
    "            device = \"cuda\"\n",
    "            compute_type = \"float16\"\n",
    "        else:\n",
    "            print(\"CUDA not available. Using CPU for transcription.\")\n",
    "            device = \"cpu\"\n",
    "            compute_type = \"auto\"\n",
    "        model = WhisperModel(\"large-v3\", device=device,\n",
    "                             compute_type=compute_type)\n",
    "        request_time = datetime.datetime.now(datetime.UTC)\n",
    "        print(\n",
    "            f\"Computing transcript for {audio_file_name} which has a {audio_file_size_mb:.2f}MB file size...\")\n",
    "        audio_duration_seconds = await get_audio_duration(audio_file_path)\n",
    "        with tqdm(total=audio_duration_seconds, desc=f\"Transcribing {audio_file_name}\", unit=\"s\") as pbar:\n",
    "            segments, info = await asyncio.to_thread(model.transcribe, audio_file_path, beam_size=10, vad_filter=True)\n",
    "            for segment in segments:\n",
    "                pbar.update(segment.end - segment.start)\n",
    "                print(\n",
    "                    f\"\\nProcessing segment: [Start: {segment.start:.2f}s, End: {segment.end:.2f}s] for file {audio_file_name} with text: {segment.text}\")\n",
    "                combined_transcript_text += segment.text + \" \"\n",
    "                sentences = sophisticated_sentence_splitter(segment.text)\n",
    "                list_of_transcript_sentences.extend(sentences)\n",
    "                metadata = {\n",
    "                    \"start\": round(segment.start, 2),\n",
    "                    \"end\": round(segment.end, 2),\n",
    "                    \"text\": segment.text,\n",
    "                    \"avg_logprob\": round(segment.avg_logprob, 2)\n",
    "                }\n",
    "                combined_transcript_text_list_of_metadata_dicts.append(\n",
    "                    metadata)\n",
    "    if not combined_transcript_text_list_of_metadata_dicts:\n",
    "        print(f\"No segments were returned for file {audio_file_name}.\")\n",
    "        return [], {}, \"\", [], datetime.datetime.now(datetime.UTC), datetime.datetime.now(datetime.UTC), 0, \"\"\n",
    "    with open(f'generated_transcript_combined_texts/{audio_file_name}.txt', 'w') as file:\n",
    "        file.write(combined_transcript_text)\n",
    "    df = pd.DataFrame(combined_transcript_text_list_of_metadata_dicts)\n",
    "    df.to_csv(\n",
    "        f'generated_transcript_metadata_tables/{audio_file_name}.csv', index=False)\n",
    "    json_file_path = f'generated_transcript_metadata_tables/{audio_file_name}.json'\n",
    "    df.to_json(json_file_path, orient='records', indent=4)\n",
    "    remove_unwanted_segments_from_json(json_file_path)\n",
    "    return combined_transcript_text, combined_transcript_text_list_of_metadata_dicts, list_of_transcript_sentences\n",
    "\n",
    "async def process_video_or_playlist(url, max_simultaneous_downloads):\n",
    "    # max_workers_transcribe = psutil.cpu_count(logical=False)  # Number of physical cores\n",
    "\n",
    "    processing_msg(single_video_url, convert_single_video, playlist_url)\n",
    "    url = single_video_url if convert_single_video else playlist_url\n",
    "\n",
    "    if convert_single_video:\n",
    "        yt = YouTube(url)\n",
    "        videos = [yt]\n",
    "    else:\n",
    "        playlist = Playlist(url)\n",
    "        videos = playlist.videos\n",
    "    download_semaphore = asyncio.Semaphore(max_simultaneous_downloads)\n",
    "\n",
    "    async def download_and_transcribe(video):\n",
    "        try:\n",
    "            async with download_semaphore:\n",
    "                audio_path, audio_filename = await download_audio(video)\n",
    "                if audio_path and audio_filename:\n",
    "                    audio_file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n",
    "                    await compute_transcript_with_whisper_from_audio_func(audio_path, audio_filename, audio_file_size_mb)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(f\"Error processing video {video.title}: {e}\")\n",
    "    \n",
    "    tasks = [download_and_transcribe(video) for video in videos]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "def normalize_logprobs(avg_logprob, min_logprob, max_logprob):\n",
    "    range_logprob = max_logprob - min_logprob\n",
    "    return (avg_logprob - min_logprob) / range_logprob if range_logprob != 0 else 0.5\n",
    "\n",
    "def remove_pagination_breaks(text: str) -> str:\n",
    "    text = re.sub(r'-(\\n)(?=[a-z])', '', text)\n",
    "    text = re.sub(r'(?<=\\w)(?<![.?!-]|\\d)\\n(?![\\nA-Z])', ' ', text)\n",
    "    return text\n",
    "\n",
    "def merge_transcript_segments_into_combined_text(segments):\n",
    "    if not segments:\n",
    "        return \"\", [], []\n",
    "    min_logprob = min(segment['avg_logprob'] for segment in segments)\n",
    "    max_logprob = max(segment['avg_logprob'] for segment in segments)\n",
    "    combined_text = \"\"\n",
    "    sentence_buffer = \"\"\n",
    "    list_of_metadata_dicts = []\n",
    "    list_of_sentences = []\n",
    "    char_count = 0\n",
    "    time_start = None\n",
    "    time_end = None\n",
    "    total_logprob = 0.0\n",
    "    segment_count = 0\n",
    "    for segment in segments:\n",
    "        if time_start is None:\n",
    "            time_start = segment['start']\n",
    "        time_end = segment['end']\n",
    "        total_logprob += segment['avg_logprob']\n",
    "        segment_count += 1\n",
    "        sentence_buffer += segment['text'] + \" \"\n",
    "        sentences = sophisticated_sentence_splitter(sentence_buffer)\n",
    "        for sentence in sentences:\n",
    "            combined_text += sentence.strip() + \" \"\n",
    "            list_of_sentences.append(sentence.strip())\n",
    "            char_count += len(sentence.strip()) + 1\n",
    "            avg_logprob = total_logprob / segment_count\n",
    "            model_confidence_score = normalize_logprobs(\n",
    "                avg_logprob, min_logprob, max_logprob)\n",
    "            metadata = {\n",
    "                'start_char_count': char_count - len(sentence.strip()) - 1,\n",
    "                'end_char_count': char_count - 2,\n",
    "                'time_start': time_start,\n",
    "                'time_end': time_end,\n",
    "                'model_confidence_score': model_confidence_score\n",
    "            }\n",
    "            list_of_metadata_dicts.append(metadata)\n",
    "        if sentences:\n",
    "            sentence_buffer = sentences.pop() if len(sentences) % 2 != 0 else \"\"\n",
    "    return combined_text, list_of_metadata_dicts, list_of_sentences\n",
    "\n",
    "def download_spacy_model(model_name=\"en_core_web_sm\"):\n",
    "    try:\n",
    "        return spacy.load(model_name)\n",
    "    except OSError:\n",
    "        print(f\"Downloading spaCy model {model_name}...\")\n",
    "        spacy.cli.download(model_name)\n",
    "        return spacy.load(model_name)\n",
    "\n",
    "def sophisticated_sentence_splitter(text):\n",
    "    if use_spacy_for_sentence_splitting:\n",
    "        nlp = download_spacy_model()\n",
    "\n",
    "        text = remove_pagination_breaks(text)\n",
    "        doc = nlp(text)\n",
    "        returned_sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    else:\n",
    "        text = remove_pagination_breaks(text)\n",
    "        pattern = r'\\.(?!\\s*(com|net|org|io)\\s)(?![0-9])'\n",
    "        pattern += r'|[.!?]\\s+'\n",
    "        pattern += r'|\\.\\.\\.(?=\\s)'\n",
    "        sentences = re.split(pattern, text)\n",
    "        refined_sentences = []\n",
    "        temp_sentence = \"\"\n",
    "        for sentence in sentences:\n",
    "            if sentence is not None:\n",
    "                temp_sentence += sentence\n",
    "                if temp_sentence.count('\"') % 2 == 0:\n",
    "                    refined_sentences.append(temp_sentence.strip())\n",
    "                    temp_sentence = \"\"\n",
    "        if temp_sentence:\n",
    "            refined_sentences.append(temp_sentence.strip())\n",
    "        returned_sentences = [s.strip() for s in refined_sentences if s.strip()]\n",
    "    return returned_sentences\n",
    "\n",
    "def handle_cuda():\n",
    "    cuda_toolkit_path = get_cuda_toolkit_path()\n",
    "    print(\"CUDA Toolkit Path:\", cuda_toolkit_path)\n",
    "\n",
    "    if cuda_toolkit_path:\n",
    "        add_to_system_path(cuda_toolkit_path)\n",
    "\n",
    "def make_dirs(paths):\n",
    "    os.makedirs(paths['audio'], exist_ok=True)\n",
    "    os.makedirs(paths['combined'], exist_ok=True)\n",
    "    os.makedirs(paths['metatable'], exist_ok=True)\n",
    "\n",
    "def processing_msg(single_video_url, convert_single_video, playlist_url):\n",
    "    process_message = 'Processing a '\n",
    "    process_message += f\"single video: {single_video_url}\" if convert_single_video else f\"playlist: {playlist_url}\"\n",
    "    print(process_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a playlist: https://www.youtube.com/playlist?list=PLC50eYMsqq-jhTtuOaLCqCdg4sz5GiwaC\n",
      "CUDA Toolkit Path: None\n",
      "\n",
      "Using local Whisper model for transcription of estrutura_do_dna_e_da_cromatina_parte_1...\n",
      "CUDA not available. Using CPU for transcription.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" The code itself \"\"\"\n",
    "\n",
    "handle_cuda()\n",
    "make_dirs(paths)\n",
    "\n",
    "await process_video_or_playlist(max_simultaneous_youtube_downloads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
